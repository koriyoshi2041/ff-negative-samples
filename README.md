# Forward-Forward Algorithm Research

> Systematic study of negative sample strategies and transfer learning in Hinton's Forward-Forward algorithm.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Overview

This project investigates two key aspects of the Forward-Forward (FF) algorithm:

1. **Negative Sample Strategies** â€” First systematic comparison of 10 different strategies
2. **Transfer Learning** â€” Why FF fails at transfer and whether Layer Collaboration helps

**Baseline Verification:** mpezeshki implementation achieves **93.25% MNIST** (1000 epochs/layer)

---

## Core Findings

### 1. CKA Analysis: Catastrophic Layer Disconnection

| Metric | FF | BP | Gap |
|--------|----|----|-----|
| Layer 0 â†” Layer 2 | **0.025** | 0.39 | 15.6Ã— worse |
| Avg Self-CKA | 0.264 | 0.592 | 2.2Ã— worse |
| Layer 2 vs BP L2 | 0.038 | â€” | Nearly alien |

**Insight:** FF layers learn in isolation â€” no information flows between layers.

```
FF:  L0 â†0.72â†’ L1 â†0.05â†’ L2   (broken chain)
BP:  L0 â†0.63â†’ L1 â†0.74â†’ L2   (coherent flow)
```

### 2. Transfer Learning: FF Weights Are Harmful

MNIST â†’ Fashion-MNIST transfer:

| Method | Transfer Acc | vs Random Init |
|--------|--------------|----------------|
| BP pretrained | 73.19% | âˆ’7.41% |
| Random init | **80.60%** | baseline |
| FF pretrained | 13.47% | **âˆ’67.13%** ğŸ”´ |
| FF + Layer Collab | 10.21% | âˆ’70.39% |

**Insight:** FF pretrained weights perform worse than random â€” they're harmful, not helpful.

### 3. Negative Sample Strategy Comparison

| Strategy | Accuracy | Uses Labels | Note |
|----------|----------|-------------|------|
| label_embedding | **38.81%** | âœ“ | Hinton's original |
| class_confusion | **38.81%** | âœ“ | 30% faster |
| random_noise | 9.80% | âœ— | Random chance |
| image_mixing | 9.80% | âœ— | Random chance |
| masking | 8.75% | âœ— | Random chance |
| adversarial | 8.75% | âœ— | Random chance |
| mono_forward | 1.10% | âœ“ | No negatives â†’ fails |

**Insight:** Label embedding is required for standard FF evaluation. Non-label strategies need linear probe evaluation.

---

## Experiment Status

| Experiment | Status | Key Result |
|------------|--------|------------|
| Baseline verification | âœ… Done | 93.25% MNIST |
| CKA analysis | âœ… Done | L0-L2 CKA = 0.025 |
| Transfer learning | âœ… Done | FF worse than random |
| Layer Collaboration | âœ… Done | Doesn't help transfer |
| Strategy comparison (9/10) | âœ… Done | Label embedding wins |
| self_contrastive | ğŸ”„ WIP | Needs linear probe |
| Linear probe for all | ğŸ“‹ Planned | â€” |
| CIFAR-10 experiments | ğŸ“‹ Planned | â€” |

---

## Project Structure

```
ff-research/
â”œâ”€â”€ negative_strategies/    # 10 strategy implementations
â”‚   â”œâ”€â”€ base.py            # Base class & registry
â”‚   â”œâ”€â”€ label_embedding.py # Hinton's original
â”‚   â”œâ”€â”€ class_confusion.py # Wrong label embedding
â”‚   â”œâ”€â”€ random_noise.py    # Noise baseline
â”‚   â”œâ”€â”€ self_contrastive.py# SCFF-style augmentation
â”‚   â””â”€â”€ ...
â”œâ”€â”€ experiments/           # Experiment scripts
â”‚   â”œâ”€â”€ ff_baseline.py     # FF baseline
â”‚   â”œâ”€â”€ transfer_experiment.py
â”‚   â”œâ”€â”€ strategy_comparison.py
â”‚   â””â”€â”€ cka_linear_probe_experiment.py
â”œâ”€â”€ analysis/              # Analysis tools
â”‚   â”œâ”€â”€ cka_analysis.py    # CKA similarity
â”‚   â””â”€â”€ linear_probe.py    # Linear probing
â”œâ”€â”€ results/               # Outputs
â”‚   â”œâ”€â”€ visualizations/    # CKA heatmaps
â”‚   â””â”€â”€ *.json             # Experiment results
â”œâ”€â”€ literature/            # Paper analyses
â”œâ”€â”€ KEY_FINDINGS.md        # Detailed findings
â””â”€â”€ EXPERIMENTS.md         # Experiment log
```

---

## Quick Start

### Installation

```bash
cd ff-research
python -m venv venv
source venv/bin/activate
pip install torch torchvision matplotlib seaborn
```

### Usage

```python
from negative_strategies import LabelEmbeddingStrategy, ClassConfusionStrategy

# All strategies share the same interface
strategy = LabelEmbeddingStrategy(num_classes=10)
positive = strategy.create_positive(images, labels)
negative = strategy.generate(images, labels)
```

### Run Experiments

```bash
# Strategy comparison
python experiments/strategy_comparison.py

# CKA analysis
python experiments/cka_linear_probe_experiment.py

# Transfer learning
python experiments/transfer_experiment.py
```

---

## References

- Hinton (2022). [The Forward-Forward Algorithm](https://arxiv.org/abs/2212.13345)
- Lorberbom et al. (2024). [Layer Collaboration in FF](https://ojs.aaai.org/index.php/AAAI/article/view/29307). AAAI 2024
- Brenig et al. (2023). [Self-Contrastive FF](https://arxiv.org/abs/2309.11955)

---

## License

MIT â€” [Shuaizhi Cheng](https://github.com/koriyoshi2041)
