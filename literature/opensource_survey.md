# FF å¼€æºå®ç°è°ƒç ”æŠ¥å‘Š

> è°ƒç ”æ—¥æœŸï¼š2026-02-05  
> ç›®æ ‡ï¼šç³»ç»Ÿæ”¶é›†å’Œåˆ†æ Forward-Forward ç®—æ³•çš„å¼€æºå®ç°ï¼Œæ‰¾åˆ°å¯å¤ç”¨ä»£ç 

---

## ğŸ“Š ä»“åº“æ¸…å•æ€»è§ˆ

| ä»“åº“ | Stars | æœ€åæ›´æ–° | æ¡†æ¶ | æ•°æ®é›† | ç‰¹ç‚¹ |
|------|-------|----------|------|--------|------|
| [mpezeshki/pytorch_forward_forward](https://github.com/mpezeshki/pytorch_forward_forward) | ~1.5k | 2023-01 | PyTorch | MNIST | æœ€æµè¡Œçš„åŸºç¡€å®ç° |
| [loeweX/Forward-Forward](https://github.com/loeweX/Forward-Forward) | ~200+ | 2023 | PyTorch | MNIST | ä»£ç è´¨é‡é«˜ï¼Œ1.45% test error |
| [andreaspapac/CwComp](https://github.com/andreaspapac/CwComp) | - | 2024 | PyTorch | MNIST/FMNIST/CIFAR-10/100 | **AAAI 2024**, CNN+ç«äº‰å­¦ä¹  |
| [neurophysics-cnrsthales/contrastive-forward-forward](https://github.com/neurophysics-cnrsthales/contrastive-forward-forward) | - | 2025 | PyTorch | MNIST/CIFAR-10/STL-10/TinyImageNet | **Nature Comm. 2025**, SCFF å®˜æ–¹ |
| [LumenPallidium/backprop-alts](https://github.com/LumenPallidium/backprop-alts) | - | 2025-01 | PyTorch | MNIST | å¤šç§ BP æ›¿ä»£æ–¹æ¡ˆå¯¹æ¯” |
| [miladsikaroudi/forward-forward-cifar](https://github.com/miladsikaroudi/forward-forward-cifar) | - | 2023 | PyTorch | CIFAR-10/100 | ä¸“æ³¨ CIFAR æ•°æ®é›† |
| [visvig/forward-forward-algorithm](https://github.com/visvig/forward-forward-algorithm) | - | 2023 | PyTorch | MNIST/CIFAR-10 | å« ConvNet å®éªŒ |
| [dslisleedh/FF-jax](https://github.com/dslisleedh/FF-jax) | - | 2023 | JAX | MNIST | JAX å®ç°ï¼Œé€‚åˆ TPU |
| [rmwkwok/forward_forward_algorithm](https://github.com/rmwkwok/forward_forward_algorithm) | - | 2023 | TensorFlow | MNIST | TF å®ç° |

---

## ğŸ” æ ¸å¿ƒä»“åº“è¯¦ç»†åˆ†æ

### 1. mpezeshki/pytorch_forward_forward â­â­â­â­â­

**æœ€æµè¡Œçš„åŸºç¡€å®ç°**

```
Stars: ~1,500
Language: Python (PyTorch)
Last Update: 2023-01
```

#### è´Ÿæ ·æœ¬ç­–ç•¥
- **Label Embedding**: å°†æ­£ç¡®/é”™è¯¯æ ‡ç­¾åµŒå…¥å›¾åƒå‰ 10 ä¸ªåƒç´ 
- æ­£æ ·æœ¬: `merge(image, correct_label)`
- è´Ÿæ ·æœ¬: `merge(image, random_wrong_label)`

#### æ”¯æŒçš„æ•°æ®é›†
- MNIST only

#### ä»£ç ç»“æ„
```python
# æ ¸å¿ƒä»£ç ç®€æ´
class Layer(nn.Linear):
    def forward(self, x):
        x_normalized = x / (x.norm(2, 1, keepdim=True) + 1e-4)
        return torch.relu(self.bn(super().forward(x_normalized)))
    
    def train(self, x_pos, x_neg):
        # å¯¹æ¯”å¼æœ¬åœ°å­¦ä¹ 
        g_pos = (self.forward(x_pos) ** 2).mean(1)
        g_neg = (self.forward(x_neg) ** 2).mean(1)
        loss = torch.log(1 + torch.exp(torch.cat([
            -g_pos + self.threshold,
            g_neg - self.threshold
        ]))).mean()
```

#### æ€§èƒ½
- Train error: 6.75%
- Test error: 6.84%

#### å¯å¤ç”¨æ€§è¯„ä¼°
| æ–¹é¢ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| ä»£ç è´¨é‡ | â­â­â­â­ | ç®€æ´æ¸…æ™°ï¼Œå•æ–‡ä»¶ |
| æ¨¡å—åŒ– | â­â­â­ | åŸºç¡€æ¨¡å—åŒ– |
| æ–‡æ¡£ | â­â­â­ | README æ¸…æ™° |
| å¯æ‰©å±• | â­â­â­ | éœ€è¦ä¿®æ”¹æ”¯æŒ CNN |

**æ¨èå€Ÿé‰´ï¼š** Layer å½’ä¸€åŒ–ã€goodness è®¡ç®—ã€åŸºç¡€æŸå¤±å‡½æ•°

---

### 2. loeweX/Forward-Forward â­â­â­â­

**é«˜è´¨é‡é‡å®ç°ï¼Œæ€§èƒ½æ›´å¥½**

```
Stars: ~200+
Language: Python (PyTorch)
Last Update: 2023
```

#### è´Ÿæ ·æœ¬ç­–ç•¥
- åŒ mpezeshkiï¼Œä½†æœ‰æ›´å¥½çš„è¶…å‚æ•°è°ƒä¼˜
- One-hot æ ‡ç­¾åµŒå…¥å‰ 10 åƒç´ 

#### æ€§èƒ½å¯¹æ¯”
| å®ç° | Test Error |
|------|------------|
| Hinton åŸè®ºæ–‡ | 1.36% |
| å®˜æ–¹ Matlab | 1.47% |
| loeweX | **1.45%** |

#### ä»£ç ç‰¹ç‚¹
- Conda ç¯å¢ƒé…ç½®å®Œå–„
- æ”¯æŒ CUDA ç‰ˆæœ¬é…ç½®
- æœ‰å®Œæ•´çš„è®­ç»ƒè„šæœ¬

**æ¨èå€Ÿé‰´ï¼š** è®­ç»ƒæµç¨‹ã€è¶…å‚æ•°è®¾ç½®

---

### 3. andreaspapac/CwComp â­â­â­â­â­

**AAAI 2024 é¡¶ä¼šè®ºæ–‡å®ç°ï¼Œå·ç§¯+ç«äº‰å­¦ä¹ **

```
Paper: AAAI 2024 (Oral + Poster)
Language: Python (PyTorch)
Last Update: 2024
License: MIT
```

#### æ ¸å¿ƒåˆ›æ–°ï¼šChannel-wise Competitive (CwC) Loss
- **æ¶ˆé™¤è´Ÿæ ·æœ¬éœ€æ±‚**ï¼ä½¿ç”¨ç«äº‰å­¦ä¹ æ›¿ä»£æ­£è´Ÿå¯¹æ¯”
- å¼•å…¥ CFSE (Channel-wise Feature Separator and Extractor) æ¨¡å—

#### è´Ÿæ ·æœ¬ç­–ç•¥
- **æ— éœ€è´Ÿæ ·æœ¬**ï¼šä½¿ç”¨ channel-wise competitive loss
- æ¯ä¸ªé€šé“å¯¹åº”ä¸€ä¸ªç±»åˆ«ï¼Œé€šè¿‡ç«äº‰å­¦ä¹ 

#### æ”¯æŒçš„æ•°æ®é›† & æ€§èƒ½
| Dataset | Test Error | è¾ƒ FF æå‡ |
|---------|------------|----------|
| MNIST | **0.58%** | æ˜¾è‘— |
| Fashion-MNIST | **7.69%** | æ˜¾è‘— |
| CIFAR-10 | **21.89%** | æ˜¾è‘— |
| CIFAR-100 | **48.77%** | æ˜¾è‘— |

#### ä»£ç ç»“æ„
```
CwComp/
â”œâ”€â”€ train_main.py      # è®­ç»ƒå…¥å£
â”œâ”€â”€ predict_main.py    # é¢„æµ‹å’Œå¯è§†åŒ–
â”œâ”€â”€ layer_cnn.py       # CNN å±‚å’ŒæŸå¤±å‡½æ•° â­
â”œâ”€â”€ layer_fc.py        # å…¨è¿æ¥å±‚
â”œâ”€â”€ datasets.py        # æ•°æ®é›†å¤„ç†
â””â”€â”€ configure.py       # é…ç½®
```

#### å¯å¤ç”¨æ€§è¯„ä¼°
| æ–¹é¢ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| ä»£ç è´¨é‡ | â­â­â­â­â­ | æ¨¡å—åŒ–ä¼˜ç§€ |
| åˆ›æ–°æ€§ | â­â­â­â­â­ | æ— éœ€è´Ÿæ ·æœ¬ï¼ |
| æ–‡æ¡£ | â­â­â­â­ | è¯¦ç»† README |
| å¯æ‰©å±• | â­â­â­â­â­ | æ”¯æŒå¤šæ•°æ®é›† |

**å¼ºçƒˆæ¨èå€Ÿé‰´ï¼š**
- `layer_cnn.py` ä¸­çš„ CwC Loss å®ç°
- CFSE æ¨¡å—è®¾è®¡
- ILT (Iterative Layer Training) ç­–ç•¥

---

### 4. neurophysics-cnrsthales/contrastive-forward-forward â­â­â­â­â­

**Nature Communications 2025 å®˜æ–¹å®ç° (SCFF)**

```
Paper: Nature Communications 16:5978 (2025)
Language: Python (PyTorch)
Python: 3.10.9, CUDA: 11.8
DOI: 10.5281/zenodo.15526033
```

#### æ ¸å¿ƒåˆ›æ–°ï¼šSelf-Contrastive è‡ªå¯¹æ¯”
- çµæ„Ÿæ¥è‡ª SimCLR ç­‰å¯¹æ¯”å­¦ä¹ 
- åŒä¸€æ ·æœ¬çš„ä¸åŒå¢å¼ºä½œä¸ºæ­£è´Ÿå¯¹
- **æ— éœ€æ ‡ç­¾çš„æ— ç›‘ç£å­¦ä¹ **

#### è´Ÿæ ·æœ¬ç­–ç•¥
- **Self-Contrastive**: æ­£æ ·æœ¬=å¼±å¢å¼ºï¼Œè´Ÿæ ·æœ¬=å¼ºå¢å¼º
- é€‚ç”¨äºå¤šç§æ•°æ®é›†ï¼Œæ— éœ€è°ƒæ•´

#### æ”¯æŒçš„æ•°æ®é›† & æ€§èƒ½
| Dataset | Accuracy | æ–¹æ³• |
|---------|----------|------|
| MNIST (MLP) | 98%+ | Greedy |
| MNIST (CNN) | 99%+ | Parallel |
| CIFAR-10 | ~85% | Parallel |
| STL-10 | ~75% | Parallel |
| Tiny ImageNet | ~40% | 2-stage |
| FSDD (Audio) | æ”¯æŒ | RNN |

#### è®­ç»ƒç­–ç•¥
1. **Greedy Layer-wise**: é€å±‚è´ªå©ªè®­ç»ƒ
2. **Parallel Training**: æ‰€æœ‰å±‚åŒæ—¶è®­ç»ƒ

#### ä»£ç ç»“æ„
```
contrastive-forward-forward/
â”œâ”€â”€ SCFF_CIFAR.py           # CIFAR è´ªå©ªè®­ç»ƒ
â”œâ”€â”€ SCFF_CIFAR_Parallel.py  # CIFAR å¹¶è¡Œè®­ç»ƒ
â”œâ”€â”€ SCFF_STL.py             # STL-10
â”œâ”€â”€ SCFF_MNIST.py           # MNIST MLP
â”œâ”€â”€ SCFF_MNIST_CNN_Parallel.py  # MNIST CNN
â”œâ”€â”€ SCFF_TIMGNET_Parallel.py    # Tiny ImageNet
â”œâ”€â”€ SCFF_FSDD.py            # éŸ³é¢‘(RNN)
â””â”€â”€ requirements.txt
```

#### å¯å¤ç”¨æ€§è¯„ä¼°
| æ–¹é¢ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| ä»£ç è´¨é‡ | â­â­â­â­ | æ¸…æ™°ä½†è¾ƒé•¿ |
| åˆ›æ–°æ€§ | â­â­â­â­â­ | è‡ªå¯¹æ¯”ï¼ŒNature çº§åˆ« |
| æ•°æ®é›†è¦†ç›– | â­â­â­â­â­ | æœ€å¹¿æ³› |
| RNN æ”¯æŒ | â­â­â­â­â­ | å”¯ä¸€æ”¯æŒåºåˆ—æ•°æ® |

**å¼ºçƒˆæ¨èå€Ÿé‰´ï¼š**
- è‡ªå¯¹æ¯”è´Ÿæ ·æœ¬ç”Ÿæˆç­–ç•¥
- Parallel training å®ç°
- RNN ç‰ˆæœ¬ FF

---

### 5. LumenPallidium/backprop-alts â­â­â­â­

**å¤šç§ BP æ›¿ä»£æ–¹æ¡ˆå¯¹æ¯”åº“**

```
Language: Python (PyTorch)
Last Update: 2025-01
```

#### åŒ…å«çš„ç®—æ³•
- Hebbian Learning (FastHebb)
- Predictive Coding (3 ç§å˜ä½“)
- Fast Weight Programmers
- Reservoir Computing
- **Forward-Forward** (å« Layer Collaboration)
- PEPITA
- Genetic Algorithms

#### FF å®ç°ç‰¹ç‚¹
- åŸºäº Hinton å®˜æ–¹ Matlab æºç 
- å®ç°äº† Layer Collaboration (arXiv:2305.12393)
- ä¸å…¶ä»–ç®—æ³•æœ‰ç»Ÿä¸€çš„å¯¹æ¯”æ¡†æ¶

#### å¯¹æ¯”ç»“æœ (4 å±‚ç½‘ç»œ, MNIST)
| ç®—æ³• | æ ·æœ¬æ•ˆç‡ | æ—¶é—´æ•ˆç‡ |
|------|----------|----------|
| Backprop | æœ€å¥½ | æœ€å¿« |
| FF | ä¸­ç­‰ | è¾ƒæ…¢ |
| Predictive Coding | å¥½ | å¾ˆæ…¢ |
| Reservoir | ä¸­ç­‰ | ä¸­ç­‰ |

**æ¨èå€Ÿé‰´ï¼š**
- Layer Collaboration å®ç°
- ç»Ÿä¸€çš„å¯¹æ¯”æ¡†æ¶è®¾è®¡

---

## ğŸ“š æœ€æ–°ç ”ç©¶è¿›å±•æ‘˜è¦

### 1. Self-Contrastive Forward-Forward (SCFF)
- **è®ºæ–‡**: Nature Communications 16:5978 (2025)
- **arXiv**: 2409.11593
- **æ ¸å¿ƒ**: ç”¨è‡ªå¯¹æ¯”å­¦ä¹ ç”Ÿæˆæ­£è´Ÿæ ·æœ¬ï¼Œæ— éœ€æ ‡ç­¾
- **æ•°æ®é›†**: MNIST, CIFAR-10, STL-10, Tiny ImageNet, FSDD
- **ä»£ç **: [å®˜æ–¹ä»“åº“](https://github.com/neurophysics-cnrsthales/contrastive-forward-forward)
- **æ„ä¹‰**: è§£å†³äº† FF åœ¨æ— ç›‘ç£åœºæ™¯çš„è´Ÿæ ·æœ¬é—®é¢˜

### 2. Mono-Forward Algorithm
- **è®ºæ–‡**: arXiv:2501.09238 (2025-01)
- **æ ¸å¿ƒ**: çº¯æœ¬åœ°å­¦ä¹ ï¼Œå•æ¬¡å‰å‘ä¼ æ’­
- **åˆ›æ–°**: æ¶ˆé™¤è´Ÿæ ·æœ¬éœ€æ±‚ï¼Œä½¿ç”¨æœ¬åœ°è¯¯å·®ä¿¡å·
- **æ€§èƒ½**: åœ¨ MNIST, FMNIST, CIFAR-10/100 ä¸ŠåŒ¹é…æˆ–è¶…è¶Š BP
- **ä¼˜åŠ¿**: å†…å­˜ä½¿ç”¨æ›´å‡åŒ€ï¼Œæ›´å¥½çš„å¹¶è¡Œæ€§

### 3. Distance-Forward Learning
- **è®ºæ–‡**: arXiv:2408.14925 (2024-08)
- **æ ¸å¿ƒ**: ç”¨è·ç¦»åº¦é‡å­¦ä¹ é‡æ„ FF
- **åˆ›æ–°**: 
  - åŸºäºè´¨å¿ƒçš„åº¦é‡å­¦ä¹ 
  - Goodness-based N-pair margin loss
  - Layer-collaboration ç­–ç•¥
- **æ€§èƒ½**:
  - MNIST: 99.7%
  - CIFAR-10: 88.2%
  - CIFAR-100: 59%
  - SVHN: 95.9%
  - ImageNette: 82.5%
- **æ„ä¹‰**: ç›®å‰ FF åœ¨è§†è§‰ä»»åŠ¡çš„ SOTA

### 4. Scalable Forward-Forward
- **è®ºæ–‡**: arXiv:2501.03176 (2025-01)
- **æ ¸å¿ƒ**: æ‰©å±• FF åˆ°ç°ä»£ CNN æ¶æ„
- **æ”¯æŒæ¶æ„**: MobileNetV3, ResNet18
- **åˆ›æ–°**: 
  - æ–°çš„å·ç§¯å±‚æŸå¤±è®¡ç®—æ–¹å¼
  - Hybrid è®¾è®¡ï¼šblock å†…ç”¨ BPï¼Œblock é—´ç”¨ FF
- **æ€§èƒ½**: ä¸æ ‡å‡† BP ç›¸å½“ï¼Œç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹æ›´å¥½
- **æ„ä¹‰**: é¦–æ¬¡å°† FF æ‰©å±•åˆ°å¤§è§„æ¨¡ç°ä»£æ¶æ„

### 5. Convolutional Channel-wise Competitive (CwComp)
- **è®ºæ–‡**: AAAI 2024 (Oral + Poster)
- **arXiv**: 2312.12668
- **æ ¸å¿ƒ**: Channel-wise ç«äº‰å­¦ä¹ æ¶ˆé™¤è´Ÿæ ·æœ¬éœ€æ±‚
- **æ€§èƒ½**: MNIST 0.58%, CIFAR-10 21.89%
- **ä»£ç **: [CwComp](https://github.com/andreaspapac/CwComp)

---

## ğŸ”§ ä¸æˆ‘ä»¬å·²æœ‰ä»£ç çš„å¯¹æ¯”

å½“å‰å®ç° (`experiments/ff_baseline.py`) åˆ†æï¼š

| ç‰¹æ€§ | æˆ‘ä»¬çš„å®ç° | æœ€ä½³å¼€æºå®ç° |
|------|-----------|-------------|
| Layer å½’ä¸€åŒ– | âœ… L2 norm | âœ… ç›¸åŒ |
| Goodness è®¡ç®— | âœ… å¹³æ–¹å’Œ | âœ… ç›¸åŒ |
| æŸå¤±å‡½æ•° | âœ… Softplus | âœ… ç›¸åŒ |
| è´Ÿæ ·æœ¬ç­–ç•¥ | å¾…æ‰©å±• | CwC(æ— éœ€), SCFF(è‡ªå¯¹æ¯”) |
| CNN æ”¯æŒ | âŒ | âœ… CwComp, SCFF |
| æ•°æ®é›† | MNIST | CIFAR-10/100, STL-10 ç­‰ |
| Layer Collaboration | âŒ | âœ… backprop-alts |
| Parallel Training | âŒ | âœ… SCFF |

---

## ğŸ“‹ æ¨èå€Ÿé‰´çš„ä»£ç æ¨¡å—

### ä¼˜å…ˆçº§ 1 (ç«‹å³å€Ÿé‰´)

1. **CwComp - Channel-wise Competitive Loss**
   - æ–‡ä»¶: `layer_cnn.py`
   - ç†ç”±: æ¶ˆé™¤è´Ÿæ ·æœ¬éœ€æ±‚ï¼Œæ€§èƒ½æœ€å¥½
   ```python
   # æ ¸å¿ƒæ€æƒ³ï¼šæ¯ä¸ªé€šé“å¯¹åº”ä¸€ä¸ªç±»åˆ«
   # é€šè¿‡ç«äº‰å­¦ä¹ è‡ªåŠ¨åŒºåˆ†
   ```

2. **SCFF - Self-Contrastive æ•°æ®å¢å¼º**
   - æ–‡ä»¶: `SCFF_CIFAR.py`
   - ç†ç”±: æ— ç›‘ç£åœºæ™¯æœ€ä½³æ–¹æ¡ˆ
   ```python
   # æ­£æ ·æœ¬ï¼šå¼±å¢å¼º (crop, flip)
   # è´Ÿæ ·æœ¬ï¼šå¼ºå¢å¼º (color jitter, blur)
   ```

### ä¼˜å…ˆçº§ 2 (è¿‘æœŸå€Ÿé‰´)

3. **CwComp - CFSE æ¨¡å—**
   - ç†ç”±: CNN ç‰¹å¾åˆ†ç¦»çš„å…³é”®æ¨¡å—

4. **SCFF - Parallel Training**
   - ç†ç”±: åŠ é€Ÿè®­ç»ƒ

5. **backprop-alts - Layer Collaboration**
   - ç†ç”±: å‡å°‘ greedy learning çš„ä¿¡æ¯æŸå¤±

### ä¼˜å…ˆçº§ 3 (é•¿æœŸå‚è€ƒ)

6. **Scalable FF çš„ Hybrid è®¾è®¡**
   - ç†ç”±: å¤§è§„æ¨¡æ¨¡å‹é€‚ç”¨

7. **Distance-Forward çš„åº¦é‡å­¦ä¹ æ¡†æ¶**
   - ç†ç”±: ç†è®ºæ›´å®Œå–„

---

## ğŸ¯ è¡ŒåŠ¨å»ºè®®

### çŸ­æœŸ (1-2 å‘¨)
1. å°† CwC Loss æ•´åˆåˆ° `ff_baseline.py`
2. æ·»åŠ  SCFF çš„è‡ªå¯¹æ¯”æ•°æ®å¢å¼º
3. æ‰©å±•æ”¯æŒ CIFAR-10

### ä¸­æœŸ (1 ä¸ªæœˆ)
4. å®ç° CNN ç‰ˆæœ¬çš„ FF (å‚è€ƒ CwComp)
5. æ·»åŠ  Layer Collaboration
6. å¯¹æ¯”å„è´Ÿæ ·æœ¬ç­–ç•¥æ€§èƒ½

### é•¿æœŸ (2-3 ä¸ªæœˆ)
7. æ¢ç´¢ Scalable FF çš„ hybrid æ¶æ„
8. ç ”ç©¶ Distance-Forward çš„åº¦é‡å­¦ä¹ æ–¹æ³•
9. åœ¨æ›´å¤§æ•°æ®é›†ä¸ŠéªŒè¯

---

## ğŸ“ é™„å½•ï¼šå…³é”®è®ºæ–‡é“¾æ¥

1. [Hinton åŸå§‹è®ºæ–‡](https://arxiv.org/abs/2212.13345) - The Forward-Forward Algorithm
2. [SCFF](https://www.nature.com/articles/s41467-025-61037-0) - Nature Communications 2025
3. [CwComp](https://arxiv.org/abs/2312.12668) - AAAI 2024
4. [Distance-Forward](https://arxiv.org/abs/2408.14925) - arXiv 2024
5. [Scalable FF](https://arxiv.org/abs/2501.03176) - arXiv 2025
6. [Mono-Forward](https://arxiv.org/abs/2501.09238) - arXiv 2025
7. [Layer Collaboration](https://arxiv.org/abs/2305.12393) - arXiv 2023
