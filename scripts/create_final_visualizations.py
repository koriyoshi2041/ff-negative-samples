#!/usr/bin/env python3
"""Create comprehensive visualizations for FF research findings."""

import matplotlib.pyplot as plt
import numpy as np
import json

# Set style
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['font.size'] = 11
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['figure.facecolor'] = 'white'

# ============================================================================
# Data from all experiments
# ============================================================================

# Fair negative strategy comparison (local, 1000 epochs)
strategies = {
    'wrong_label': 94.50,
    'class_confusion': 92.15,
    'same_class_diff_img': 92.06,
    'hybrid_mix': 63.37,
    'noise_augmented': 46.10,
    'masked': 30.97
}

# Transfer learning comparison
transfer_data = {
    'CwC-FF [Hinton]': {'mnist': 98.71, 'transfer': 89.05, 'vs_random': 17.16},
    'Random Init': {'mnist': 0, 'transfer': 71.89, 'vs_random': 0},
    'Backprop': {'mnist': 95.08, 'transfer': 75.49, 'vs_random': 3.60},
    'Standard FF': {'mnist': 89.90, 'transfer': 54.19, 'vs_random': -17.70},
}

# Bio-inspired variants (A100 results)
bio_variants = {
    'Three-Factor\n(top_down)': {'mnist': 91.08, 'transfer': 64.32, 'status': 'marginal'},
    'Three-Factor\n(baseline)': {'mnist': 89.66, 'transfer': 62.81, 'status': 'baseline'},
    'Layer Collab\n(Î³=0.7)': {'mnist': 91.56, 'transfer': None, 'status': 'marginal'},
    'Prospective FF\n(500 iter)': {'mnist': 91.30, 'transfer': 76.52, 'status': 'marginal'},
    'PCL-FF': {'mnist': 17.50, 'transfer': 11.87, 'status': 'failed'},
    'Three-Factor\n(reward)': {'mnist': 10.28, 'transfer': 18.44, 'status': 'failed'},
}

# Efficiency comparison
efficiency = {
    'Backprop': {'epochs': 50, 'time': 2, 'accuracy': 99.2},
    'Standard FF': {'epochs': 3000, 'time': 60, 'accuracy': 94.5},
    'CwC-FF': {'epochs': 3000, 'time': 90, 'accuracy': 98.7},
    'Prospective FF': {'epochs': 3000, 'time': 480, 'accuracy': 91.3},
}

# ============================================================================
# Figure 1: Bio-Inspired Variants Summary (Main Result)
# ============================================================================

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Panel 1: MNIST Accuracy
ax1 = axes[0]
variants = list(bio_variants.keys())
mnist_accs = [bio_variants[v]['mnist'] for v in variants]
colors = ['#2ecc71' if bio_variants[v]['status'] == 'marginal' else
          '#95a5a6' if bio_variants[v]['status'] == 'baseline' else
          '#e74c3c' for v in variants]

bars = ax1.barh(variants, mnist_accs, color=colors, edgecolor='black', linewidth=0.5)
ax1.axvline(x=89.66, color='gray', linestyle='--', alpha=0.7, label='Baseline (89.66%)')
ax1.set_xlabel('MNIST Accuracy (%)')
ax1.set_title('A. Source Task Performance')
ax1.set_xlim(0, 100)
for i, (bar, acc) in enumerate(zip(bars, mnist_accs)):
    ax1.text(acc + 1, i, f'{acc:.1f}%', va='center', fontsize=10)

# Panel 2: Transfer Accuracy
ax2 = axes[1]
transfer_accs = [bio_variants[v]['transfer'] if bio_variants[v]['transfer'] else 0 for v in variants]
bars = ax2.barh(variants, transfer_accs, color=colors, edgecolor='black', linewidth=0.5)
ax2.axvline(x=62.81, color='gray', linestyle='--', alpha=0.7, label='Baseline (62.81%)')
ax2.axvline(x=71.89, color='blue', linestyle=':', alpha=0.7, label='Random Init (71.89%)')
ax2.set_xlabel('Fashion-MNIST Transfer (%)')
ax2.set_title('B. Transfer Learning Performance')
ax2.set_xlim(0, 100)
for i, (bar, acc) in enumerate(zip(bars, transfer_accs)):
    if acc > 0:
        ax2.text(acc + 1, i, f'{acc:.1f}%', va='center', fontsize=10)

# Panel 3: Summary Legend
ax3 = axes[2]
ax3.axis('off')

summary_text = """
Key Findings from Bio-Inspired FF Variants:

âœ… MARGINAL SUCCESS (+1-2%)
â€¢ Three-Factor (top_down): +1.5% transfer
â€¢ Layer Collaboration (Î³=0.7): +1.2% MNIST
â€¢ Prospective FF: +1.8% MNIST

ğŸ’€ COMPLETE FAILURE
â€¢ PCL-FF: 100% neuron death
â€¢ Reward Prediction: Learning collapse

ğŸ¯ ROOT CAUSE
Standard FF's label embedding creates
task-specific features that cannot transfer.

Bio-inspired modifications address symptoms,
not the fundamental design flaw.

ğŸ“Œ SOLUTION
Only CwC-FF (89% transfer) worksâ€”
by completely abandoning label embedding.
"""

ax3.text(0.1, 0.95, summary_text, transform=ax3.transAxes, fontsize=11,
         verticalalignment='top', fontfamily='monospace',
         bbox=dict(boxstyle='round', facecolor='#f8f9fa', edgecolor='#dee2e6'))

plt.suptitle('Bio-Inspired FF Variants: Systematic Evaluation', fontsize=16, fontweight='bold', y=1.02)
plt.tight_layout()
plt.savefig('figures/bio_inspired_summary.png', dpi=150, bbox_inches='tight', facecolor='white')
plt.close()
print("âœ“ Saved figures/bio_inspired_summary.png")

# ============================================================================
# Figure 2: The Three Barriers (Why FF Hasn't Become Paradigm)
# ============================================================================

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Panel 1: Performance Gap
ax1 = axes[0]
models = ['Backprop', 'CwC-FF\n[Hinton]', 'Standard FF', 'Prospective\nFF', 'PCL-FF']
accs = [99.2, 98.7, 94.5, 91.3, 17.5]
colors = ['#3498db', '#2ecc71', '#f39c12', '#e67e22', '#e74c3c']
bars = ax1.bar(models, accs, color=colors, edgecolor='black', linewidth=0.5)
ax1.set_ylabel('MNIST Accuracy (%)')
ax1.set_title('Barrier 1: Performance Gap', fontweight='bold')
ax1.set_ylim(0, 105)
for bar, acc in zip(bars, accs):
    ax1.text(bar.get_x() + bar.get_width()/2, acc + 1, f'{acc}%',
             ha='center', va='bottom', fontsize=10)
ax1.axhline(y=99.2, color='#3498db', linestyle='--', alpha=0.5)

# Panel 2: Efficiency Problem
ax2 = axes[1]
models = ['Backprop', 'Standard FF', 'CwC-FF', 'Prospective FF']
times = [2, 60, 90, 480]
colors = ['#3498db', '#f39c12', '#2ecc71', '#e67e22']
bars = ax2.bar(models, times, color=colors, edgecolor='black', linewidth=0.5)
ax2.set_ylabel('Training Time (minutes)')
ax2.set_title('Barrier 2: Training Inefficiency', fontweight='bold')
for bar, t in zip(bars, times):
    label = f'{t}min' if t < 60 else f'{t//60}h{t%60}m' if t >= 60 else f'{t}min'
    ax2.text(bar.get_x() + bar.get_width()/2, t + 10, f'{t}min\n({t//2}Ã—)' if t > 2 else '2min\n(1Ã—)',
             ha='center', va='bottom', fontsize=9)

# Panel 3: Transfer Failure
ax3 = axes[2]
models = ['CwC-FF\n[Hinton]', 'Backprop', 'Random\nInit', 'Standard\nFF']
transfers = [89.05, 75.49, 71.89, 54.19]
colors = ['#2ecc71', '#3498db', '#95a5a6', '#e74c3c']
bars = ax3.bar(models, transfers, color=colors, edgecolor='black', linewidth=0.5)
ax3.set_ylabel('Fashion-MNIST Transfer (%)')
ax3.set_title('Barrier 3: Transfer Failure', fontweight='bold')
ax3.axhline(y=71.89, color='gray', linestyle='--', alpha=0.7, label='Random Init')
ax3.set_ylim(0, 100)
for bar, t in zip(bars, transfers):
    ax3.text(bar.get_x() + bar.get_width()/2, t + 1, f'{t:.1f}%',
             ha='center', va='bottom', fontsize=10)

plt.suptitle('Why Forward-Forward Hasn\'t Become the New Paradigm',
             fontsize=16, fontweight='bold', y=1.02)
plt.tight_layout()
plt.savefig('figures/three_barriers.png', dpi=150, bbox_inches='tight', facecolor='white')
plt.close()
print("âœ“ Saved figures/three_barriers.png")

# ============================================================================
# Figure 3: Negative Sampling Strategy Comparison
# ============================================================================

fig, ax = plt.subplots(figsize=(10, 6))

names = list(strategies.keys())
accs = list(strategies.values())
colors = ['#2ecc71' if a > 90 else '#f39c12' if a > 50 else '#e74c3c' for a in accs]

bars = ax.barh(names, accs, color=colors, edgecolor='black', linewidth=0.5)
ax.set_xlabel('Test Accuracy (%)')
ax.set_title('Fair Comparison: Negative Sampling Strategies\n(1000 epochs, identical positive samples)',
             fontweight='bold')
ax.set_xlim(0, 100)

for i, (bar, acc) in enumerate(zip(bars, accs)):
    ax.text(acc + 1, i, f'{acc:.2f}%', va='center', fontsize=11, fontweight='bold')

# Add rank labels
for i, name in enumerate(names):
    rank = i + 1
    medal = 'ğŸ¥‡' if rank == 1 else 'ğŸ¥ˆ' if rank == 2 else 'ğŸ¥‰' if rank == 3 else f'#{rank}'
    ax.text(2, i, medal, va='center', fontsize=12)

ax.text(0.98, 0.02, 'Conclusion: Hinton\'s simple wrong-label method is optimal.\nComplex negative generation hurts performance.',
        transform=ax.transAxes, fontsize=10, ha='right', va='bottom',
        bbox=dict(boxstyle='round', facecolor='#f0f0f0', alpha=0.8))

plt.tight_layout()
plt.savefig('figures/negative_strategy_fair.png', dpi=150, bbox_inches='tight', facecolor='white')
plt.close()
print("âœ“ Saved figures/negative_strategy_fair.png")

# ============================================================================
# Figure 4: Complete Experiment Summary (Radar/Spider Chart)
# ============================================================================

fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(polar=True))

categories = ['MNIST\nAccuracy', 'Transfer\nAccuracy', 'Training\nEfficiency',
              'Scalability', 'Biological\nPlausibility']
N = len(categories)

# Normalize scores to 0-1
models_radar = {
    'Backprop': [1.0, 0.84, 1.0, 1.0, 0.0],
    'Standard FF': [0.95, 0.0, 0.03, 0.3, 1.0],
    'CwC-FF': [0.99, 1.0, 0.02, 0.3, 0.7],
    'Three-Factor FF': [0.92, 0.15, 0.02, 0.3, 0.9],
}

angles = [n / float(N) * 2 * np.pi for n in range(N)]
angles += angles[:1]

colors = {'Backprop': '#3498db', 'Standard FF': '#e74c3c',
          'CwC-FF': '#2ecc71', 'Three-Factor FF': '#9b59b6'}

for model, values in models_radar.items():
    values += values[:1]
    ax.plot(angles, values, 'o-', linewidth=2, label=model, color=colors[model])
    ax.fill(angles, values, alpha=0.1, color=colors[model])

ax.set_xticks(angles[:-1])
ax.set_xticklabels(categories, size=11)
ax.set_ylim(0, 1)
ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
ax.set_title('Multi-Dimensional Comparison of Learning Algorithms',
             fontsize=14, fontweight='bold', pad=20)

plt.tight_layout()
plt.savefig('figures/radar_comparison_full.png', dpi=150, bbox_inches='tight', facecolor='white')
plt.close()
print("âœ“ Saved figures/radar_comparison_full.png")

# ============================================================================
# Figure 5: Lessons from Failures
# ============================================================================

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Panel 1: PCL-FF Neuron Death
ax1 = axes[0]
layers = ['Layer 0', 'Layer 1']
dead_neurons = [99.8, 100.0]
alive_neurons = [0.2, 0.0]

x = np.arange(len(layers))
width = 0.6

bars_dead = ax1.bar(x, dead_neurons, width, label='Dead Neurons', color='#e74c3c')
bars_alive = ax1.bar(x, alive_neurons, width, bottom=dead_neurons, label='Active Neurons', color='#2ecc71')

ax1.set_ylabel('Neuron Status (%)')
ax1.set_title('PCL-FF: Complete Neuron Death\n(Sparsity constraint too aggressive)', fontweight='bold')
ax1.set_xticks(x)
ax1.set_xticklabels(layers)
ax1.legend()
ax1.set_ylim(0, 105)

for bar in bars_dead:
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height/2, f'{height:.1f}%',
             ha='center', va='center', color='white', fontweight='bold', fontsize=12)

# Add lesson box
lesson1 = "Lesson: Excessive sparsity constraints\nkill learning entirely. Balance is crucial."
ax1.text(0.5, -0.15, lesson1, transform=ax1.transAxes, ha='center', fontsize=10,
         bbox=dict(boxstyle='round', facecolor='#fff3cd', edgecolor='#ffc107'))

# Panel 2: Reward Prediction Collapse
ax2 = axes[1]
modulations = ['Baseline\n(none)', 'Top-Down', 'Layer\nAgreement', 'Reward\nPrediction']
mnist_accs = [89.66, 91.08, 89.58, 10.28]
colors = ['#95a5a6', '#2ecc71', '#f39c12', '#e74c3c']

bars = ax2.bar(modulations, mnist_accs, color=colors, edgecolor='black', linewidth=0.5)
ax2.set_ylabel('MNIST Accuracy (%)')
ax2.set_title('Three-Factor FF: Modulation Type Comparison\n(Reward prediction causes collapse)', fontweight='bold')
ax2.set_ylim(0, 100)

for bar, acc in zip(bars, mnist_accs):
    ax2.text(bar.get_x() + bar.get_width()/2., acc + 2, f'{acc:.1f}%',
             ha='center', va='bottom', fontsize=11, fontweight='bold')

# Add lesson box
lesson2 = "Lesson: Not all biological mechanisms help.\nReward signal can destabilize local learning."
ax2.text(0.5, -0.15, lesson2, transform=ax2.transAxes, ha='center', fontsize=10,
         bbox=dict(boxstyle='round', facecolor='#fff3cd', edgecolor='#ffc107'))

plt.suptitle('Learning from Failures: What Doesn\'t Work', fontsize=14, fontweight='bold', y=1.02)
plt.tight_layout()
plt.savefig('figures/lessons_from_failures.png', dpi=150, bbox_inches='tight', facecolor='white')
plt.close()
print("âœ“ Saved figures/lessons_from_failures.png")

# ============================================================================
# Figure 6: Final Summary - The Path Forward
# ============================================================================

fig, ax = plt.subplots(figsize=(12, 8))
ax.axis('off')

summary = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    WHY FORWARD-FORWARD HASN'T BECOME THE NEW PARADIGM                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                          â•‘
â•‘  EXPERIMENTS CONDUCTED                          KEY FINDINGS                             â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                             â•‘
â•‘  âœ“ 6 negative sampling strategies              â€¢ Hinton's wrong-label is optimal (94.5%)â•‘
â•‘  âœ“ 5 bio-inspired FF variants                  â€¢ Standard FF transfers WORSE than randomâ•‘
â•‘  âœ“ Transfer learning (MNISTâ†’F-MNIST)           â€¢ Bio-inspired fixes: marginal (+1-2%)   â•‘
â•‘  âœ“ Efficiency benchmarking                     â€¢ FF is 30-240Ã— slower than backprop     â•‘
â•‘                                                                                          â•‘
â•‘  THE THREE BARRIERS                             FAILED APPROACHES                        â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â•‘
â•‘  ğŸ”´ Performance: 94.5% vs 99.2% (MNIST)        âœ— PCL-FF: 100% neuron death              â•‘
â•‘  ğŸ”´ Efficiency: 60Ã— more epochs needed         âœ— Reward prediction: learning collapse   â•‘
â•‘  ğŸ”´ Transfer: 54% vs 72% (worse than random)   âœ— Prospective FF: negative transfer gain â•‘
â•‘                                                                                          â•‘
â•‘  ROOT CAUSE                                     THE SOLUTION                             â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                             â•‘
â•‘  Label embedding couples features to           CwC-FF achieves 89% transfer by          â•‘
â•‘  source task labels â†’ no generalization        ABANDONING label embedding entirely      â•‘
â•‘                                                                                          â•‘
â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â•‘
â•‘  CONCLUSION: FF is a beautiful idea, but its core design (label embedding) is flawed.   â•‘
â•‘  Future work should focus on label-free, efficient variants.                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

ax.text(0.5, 0.5, summary, transform=ax.transAxes, fontsize=11,
        verticalalignment='center', horizontalalignment='center',
        fontfamily='monospace',
        bbox=dict(boxstyle='round', facecolor='#f8f9fa', edgecolor='#343a40', linewidth=2))

plt.savefig('figures/final_summary.png', dpi=150, bbox_inches='tight', facecolor='white')
plt.close()
print("âœ“ Saved figures/final_summary.png")

print("\n" + "="*60)
print("All visualizations created successfully!")
print("="*60)
