# RQ1: Why Does Forward-Forward Fail at Transfer Learning?

**è°ƒç ”æ—¥æœŸ:** 2026-02-04  
**ç ”ç©¶é—®é¢˜:** FF ç®—æ³•åœ¨è¿ç§»å­¦ä¹ ä¸­å¤±è´¥çš„åŸå› åˆ†æ

---

## 1. æ ¸å¿ƒå‘ç°æ€»ç»“

### ğŸ”‘ å…³é”®è®ºæ–‡å‘ç°

**æœ€ç›´æ¥ç›¸å…³çš„è®ºæ–‡:**
- **[Brenig et al., 2023] "A Study of Forward-Forward Algorithm for Self-Supervised Learning"** (arXiv:2309.11955)
  - **æ ¸å¿ƒå‘ç°:** "While the forward-forward algorithm performs comparably to backpropagation during (self-)supervised training, **the transfer performance is significantly lagging behind in all the studied settings**."
  - æµ‹è¯•æ•°æ®é›†: MNIST, F-MNIST, SVHN, CIFAR-10
  - è‡ªç›‘ç£æ–¹æ³•: rotation, flip, jigsaw

### FF è¿ç§»æ€§èƒ½å·®çš„å…·ä½“è¡¨ç°

| è®­ç»ƒè®¾ç½® | æºä»»åŠ¡æ€§èƒ½ | è¿ç§»æ€§èƒ½ |
|---------|-----------|---------|
| FF supervised | ä¸ BP ç›¸å½“ | **æ˜¾è‘—è½å** |
| FF self-supervised | ä¸ BP ç›¸å½“ | **æ˜¾è‘—è½å** |
| FF rotation pretext | å¯æ¥å— | å·® |
| FF jigsaw pretext | å¯æ¥å— | å·® |

---

## 2. FF è¿ç§»å­¦ä¹ å¤±è´¥çš„åŸå› åˆ†æ

### 2.1 å±‚é—´ä¿¡æ¯æ–­è£‚ (Layer Collaboration Problem)

**å…³é”®è®ºæ–‡:** [Lorberbom et al., AAAI 2024] "Layer Collaboration in the Forward-Forward Algorithm"

**æ ¸å¿ƒé—®é¢˜:**
> "The forward-forward algorithm permits communication between layers **only through the forward pass** because each layer only takes into account the output of its predecessor... the forward-forward process does not enable the **flow of information to earlier layers** (i.e., layers closer to the data)"

**æŠ€æœ¯ç»†èŠ‚:**
1. **å•å‘ä¿¡æ¯æµ:** FF ä¸­æ¯å±‚ç‹¬ç«‹ä¼˜åŒ–è‡ªå·±çš„ goodness function
2. **æ— åå‘ä¿¡å·:** æ²¡æœ‰ç±»ä¼¼ BP çš„æ¢¯åº¦æµå°†ä»»åŠ¡ä¿¡æ¯ä¼ å›æ—©æœŸå±‚
3. **å±€éƒ¨æœ€ä¼˜:** æ¯å±‚å¯èƒ½é™·å…¥å¯¹å½“å‰ä»»åŠ¡æœ‰æ•ˆä½†ä¸é€šç”¨çš„å±€éƒ¨æœ€ä¼˜

**æ•°å­¦è¡¨è¾¾:**
- BP: $\frac{\partial L}{\partial W_l} = \frac{\partial L}{\partial a_L} \cdot \frac{\partial a_L}{\partial a_{L-1}} \cdots \frac{\partial a_{l+1}}{\partial W_l}$ (å…¨å±€æ¢¯åº¦æµ)
- FF: $\frac{\partial G_l}{\partial W_l}$ (ä»…å±€éƒ¨æ¢¯åº¦ï¼Œå±‚é—´ç‹¬ç«‹)

### 2.2 ç‰¹å¾è¿‡äº Task-Specific

**æ¥è‡ª Brenig et al. çš„åˆ†æ:**
> "In comparison to backpropagation, the forward-forward algorithm **focuses more on the boundaries** and **drops part of the information unnecessary for making decisions** which harms the representation learning goal."

**è¡¨ç°:**
1. FF å­¦åˆ°çš„ç‰¹å¾æ›´å…³æ³¨"è¾¹ç•Œ"ä¿¡æ¯ï¼ˆç”¨äºåŒºåˆ† positive/negativeï¼‰
2. ä¸¢å¼ƒäº†å¯¹å½“å‰ä»»åŠ¡"ä¸å¿…è¦"ä½†å¯¹è¿ç§»æœ‰ä»·å€¼çš„ä¿¡æ¯
3. ç‰¹å¾è¿‡äºä¸“æ³¨äº goodness score çš„ä¼˜åŒ–ï¼Œè€Œéé€šç”¨è¡¨å¾

### 2.3 ä¸ BP æ¢¯åº¦æµçš„æœ¬è´¨åŒºåˆ«

| ç‰¹æ€§ | Backpropagation | Forward-Forward |
|-----|-----------------|-----------------|
| **æ¢¯åº¦æ–¹å‘** | å…¨å±€ï¼Œä» loss åä¼  | å±€éƒ¨ï¼Œæ¯å±‚ç‹¬ç«‹ |
| **å±‚é—´ä¾èµ–** | å¼ºè€¦åˆï¼ˆé“¾å¼æ³•åˆ™ï¼‰ | å¼±è€¦åˆï¼ˆä»…å‰å‘ä¼ é€’ï¼‰ |
| **ä¿¡æ¯æµ** | åŒå‘ï¼ˆå‰å‘+åå‘ï¼‰ | å•å‘ï¼ˆä»…å‰å‘ï¼‰ |
| **ä¼˜åŒ–ç›®æ ‡** | å•ä¸€å…¨å±€ loss | å¤šä¸ªå±€éƒ¨ goodness |
| **ç‰¹å¾å­¦ä¹ ** | ç«¯åˆ°ç«¯ï¼Œä¸ºæœ€ç»ˆä»»åŠ¡ä¼˜åŒ– | é€å±‚ï¼Œä¸ºå±€éƒ¨ç›®æ ‡ä¼˜åŒ– |

**BP çš„å…³é”®ä¼˜åŠ¿:**
- æ¢¯åº¦é“¾æ¥æ‰€æœ‰å±‚ï¼Œå½¢æˆ"ä¿¡æ¯é«˜é€Ÿå…¬è·¯"
- æ—©æœŸå±‚èƒ½"æ„ŸçŸ¥"åæœŸå±‚çš„éœ€æ±‚
- ç‰¹å¾è‡ªç„¶åœ°ä»é€šç”¨è¿‡æ¸¡åˆ°ç‰¹å®š

**FF çš„å…³é”®åŠ£åŠ¿:**
- æ¯å±‚"ç›²ç›®"ä¼˜åŒ–ï¼Œä¸çŸ¥é“åç»­å±‚çš„éœ€æ±‚
- æ—©æœŸå±‚å¯èƒ½ä¸¢å¼ƒå¯¹ä¸‹æ¸¸ä»»åŠ¡é‡è¦çš„ä¿¡æ¯
- æ²¡æœ‰æœºåˆ¶é¼“åŠ±å­¦ä¹ é€šç”¨ç‰¹å¾

### 2.4 Goodness Function çš„å±€é™æ€§

**åŸå§‹ FF çš„ Goodness:**
$$G = \sum_j a_j^2$$

**é—®é¢˜:**
1. ä»…å…³æ³¨æ¿€æ´»å€¼å¤§å°ï¼Œä¸å…³æ³¨è¡¨å¾è´¨é‡
2. æ­£è´Ÿæ ·æœ¬çš„åŒºåˆ†å¯èƒ½é€šè¿‡"æ·å¾„"å®ç°
3. æ²¡æœ‰æ˜¾å¼é¼“åŠ±å±‚é—´åä½œæˆ–ç‰¹å¾å¤šæ ·æ€§

---

## 3. è¡¨å¾åˆ†ææ–¹æ³•

### 3.1 CKA (Centered Kernel Alignment)

**å®šä¹‰:**
$$\text{CKA}(K, L) = \frac{\text{HSIC}(K, L)}{\sqrt{\text{HSIC}(K, K) \cdot \text{HSIC}(L, L)}}$$

**ç”¨é€”:**
- æ¯”è¾ƒä¸¤ä¸ªç½‘ç»œ/å±‚çš„è¡¨å¾ç›¸ä¼¼åº¦
- è¯„ä¼°è¿ç§»å­¦ä¹ ä¸­ç‰¹å¾çš„å¯¹é½ç¨‹åº¦
- åˆ†æ FF vs BP å­¦åˆ°çš„è¡¨å¾å·®å¼‚

**ä¼˜åŠ¿:**
- å¯¹æ­£äº¤å˜æ¢ä¸å˜
- å¯æ¯”è¾ƒä¸åŒç»´åº¦çš„è¡¨å¾
- é€‚åˆåˆ†æå±‚çº§ç»“æ„

**å‚è€ƒå®ç°:** 
```python
# ä½¿ç”¨ Google çš„ CKA å®ç°
# https://github.com/google-research/google-research/tree/master/representation_similarity
```

### 3.2 RSA (Representational Similarity Analysis)

**å®šä¹‰:**
å°†é«˜ç»´ç¥ç»æ´»åŠ¨è½¬åŒ–ä¸º **è¡¨å¾ä¸ç›¸ä¼¼çŸ©é˜µ (RDM)**ï¼Œç”¨äºè·¨ç³»ç»Ÿæ¯”è¾ƒã€‚

**æµç¨‹:**
1. è®¡ç®—æ‰€æœ‰æ ·æœ¬å¯¹çš„è¡¨å¾ç›¸ä¼¼åº¦
2. æ„å»º RDMï¼ˆä¸ç›¸ä¼¼åº¦çŸ©é˜µï¼‰
3. æ¯”è¾ƒä¸åŒæ¨¡å‹/å±‚çš„ RDM

**ç”¨é€”:**
- åˆ†æ FF å„å±‚çš„è¡¨å¾ç»“æ„
- æ¯”è¾ƒ FF å’Œ BP çš„è¡¨å¾å‡ ä½•
- è¯„ä¼°ç‰¹å¾çš„è¯­ä¹‰ç»„ç»‡æ€§

### 3.3 å…¶ä»–ç›¸å…³æ–¹æ³•

| æ–¹æ³• | ç”¨é€” | è®ºæ–‡ |
|-----|-----|-----|
| **Linear Probing** | è¯„ä¼°ç‰¹å¾çš„çº¿æ€§å¯åˆ†æ€§ | æ ‡å‡†å®è·µ |
| **FrÃ©chet Distance** | åˆ†æè¿ç§»æ€§ | [Ding et al., WACV 2021] |
| **QUANTA** | é‡åŒ–ç‰¹å¾è¿ç§»æ€§ | [ScienceDirect, 2021] |
| **Activation Statistics** | åˆ†ææ¿€æ´»åˆ†å¸ƒ | æ ‡å‡†å®è·µ |

---

## 4. è¿ç§»æ€§é‡åŒ–æ–¹æ³•

### 4.1 ç»å…¸æ–¹æ³• (Yosinski et al., 2014)

**å®éªŒè®¾è®¡:**
- è®­ç»ƒæºç½‘ç»œ (Task A)
- å†»ç»“å‰ n å±‚ï¼Œè¿ç§»åˆ°ç›®æ ‡ä»»åŠ¡ (Task B)
- æµ‹é‡æ€§èƒ½å˜åŒ–

**å…³é”®å‘ç°:**
1. **ä½å±‚ç‰¹å¾é€šç”¨:** ç±»ä¼¼ Gabor filtersï¼Œå¯¹å¤šä»»åŠ¡æœ‰æ•ˆ
2. **é«˜å±‚ç‰¹å¾ç‰¹å®š:** ä¸“é—¨ä¸ºæºä»»åŠ¡ä¼˜åŒ–
3. **Co-adaptation é—®é¢˜:** ä¸­é—´å±‚åˆ†å‰²å¯èƒ½å¯¼è‡´ä¼˜åŒ–å›°éš¾

### 4.2 é’ˆå¯¹ FF çš„è¿ç§»æ€§æµ‹é‡

**æ¨èå®éªŒæµç¨‹:**
```
1. åœ¨ Dataset A ä¸Šè®­ç»ƒ FF ç½‘ç»œ
2. å†»ç»“ä¸åŒå±‚æ•°ï¼Œåœ¨ Dataset B ä¸Šå¾®è°ƒ
3. ä¸ BP baseline æ¯”è¾ƒ
4. ä½¿ç”¨ CKA/RSA åˆ†æè¡¨å¾å·®å¼‚
```

**æµ‹é‡æŒ‡æ ‡:**
- **è¿ç§»å‡†ç¡®ç‡å·®:** $\Delta_{acc} = Acc_{BP} - Acc_{FF}$
- **å±‚çº§è¿ç§»æ›²çº¿:** æ¯å±‚å†»ç»“çš„è¿ç§»æ€§èƒ½
- **CKA ç›¸ä¼¼åº¦:** FF vs BP çš„è¡¨å¾å¯¹é½

---

## 5. å®éªŒè®¾è®¡æ–¹æ¡ˆ

### 5.1 æ•°æ®é›†é€‰æ‹©

| æºæ•°æ®é›† | ç›®æ ‡æ•°æ®é›† | éš¾åº¦ | åŸå›  |
|---------|-----------|-----|------|
| **CIFAR-10** | **CIFAR-100** | ä¸­ç­‰ | åŒæºä¸åŒç²’åº¦ï¼Œæ ‡å‡†è¿ç§»æµ‹è¯• |
| CIFAR-10 | STL-10 | ä¸­ç­‰ | ç›¸ä¼¼ç±»åˆ«ï¼Œä¸åŒåˆ†è¾¨ç‡ |
| MNIST | Fashion-MNIST | ä½ | åŒç»“æ„ä¸åŒè¯­ä¹‰ |
| ImageNet-100 | CIFAR-100 | é«˜ | è·¨åŸŸè¿ç§» |

**æ¨è:** å…ˆç”¨ **CIFAR-10 â†’ CIFAR-100** ä½œä¸ºä¸»å®éªŒ

### 5.2 å®éªŒä¸€ï¼šåŸºç¡€è¿ç§»æ€§èƒ½å¯¹æ¯”

**ç›®æ ‡:** é‡åŒ– FF vs BP çš„è¿ç§»æ€§èƒ½å·®è·

**è®¾ç½®:**
```python
# ç½‘ç»œæ¶æ„
model = MLP(
    layers=[784, 500, 500, 500, 10],  # æˆ– CNN
    activation='relu'
)

# è®­ç»ƒåè®®
source_task = 'CIFAR-10'
target_task = 'CIFAR-100'

# è¿ç§»ç­–ç•¥
strategies = [
    'freeze_all_finetune_head',      # å†»ç»“ç‰¹å¾ï¼Œä»…è®­ç»ƒåˆ†ç±»å¤´
    'freeze_early_finetune_late',    # å†»ç»“æ—©æœŸå±‚
    'full_finetune',                 # å…¨å‚æ•°å¾®è°ƒ
]
```

**æŒ‡æ ‡:**
- Top-1 Accuracy
- Top-5 Accuracy
- Learning Curve (æ”¶æ•›é€Ÿåº¦)

### 5.3 å®éªŒäºŒï¼šå±‚çº§è¡¨å¾åˆ†æ

**ç›®æ ‡:** åˆ†æ FF å„å±‚å­¦åˆ°çš„ç‰¹å¾è´¨é‡

**æ–¹æ³•:**
```python
# 1. CKA åˆ†æ
for layer in model.layers:
    cka_ff_bp = compute_cka(ff_activations[layer], bp_activations[layer])
    cka_ff_random = compute_cka(ff_activations[layer], random_activations[layer])

# 2. Linear Probing
for layer in model.layers:
    probe_acc = train_linear_probe(ff_activations[layer], labels)
    
# 3. RSA åˆ†æ
for layer in model.layers:
    rdm = compute_rdm(ff_activations[layer])
    compare_to_semantic_rdm(rdm, category_similarity)
```

**è¾“å‡º:**
- CKA çƒ­åŠ›å›¾ (FF vs BP å„å±‚)
- Linear probing æ›²çº¿
- RDM å¯è§†åŒ–

### 5.4 å®éªŒä¸‰ï¼šç‰¹å¾é€šç”¨æ€§ vs ç‰¹å®šæ€§

**ç›®æ ‡:** éªŒè¯ FF ç‰¹å¾æ˜¯å¦è¿‡äº task-specific

**è®¾è®¡:**
```python
# åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šæµ‹è¯•åŒä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹
pretrained_model = train_ff(CIFAR10)

downstream_tasks = [
    'CIFAR-100',
    'STL-10',
    'SVHN',
    'MNIST'  # æç«¯ä¸åŒçš„ä»»åŠ¡
]

for task in downstream_tasks:
    transfer_acc[task] = evaluate_transfer(pretrained_model, task)
```

**å‡è®¾:**
- å¦‚æœ FF ç‰¹å¾è¿‡äºç‰¹å®šï¼Œåœ¨ä¸åŒä»»åŠ¡ä¸Šæ€§èƒ½ä¸‹é™æ›´å¿«
- BP ç‰¹å¾åº”è¯¥å±•ç°æ›´å¹³æ»‘çš„"è¿ç§»è¡°å‡æ›²çº¿"

### 5.5 å®éªŒå››ï¼šå±‚åä½œæ”¹è¿›

**ç›®æ ‡:** æµ‹è¯•æ”¹è¿›çš„ FF å˜ä½“æ˜¯å¦æå‡è¿ç§»æ€§

**å˜ä½“:**
1. **åŸå§‹ FF** (Hinton, 2022)
2. **Layer Collaboration FF** (AAAI 2024)
3. **PEPITA** (å¦‚é€‚ç”¨)
4. **Scalable FF** (2025)

**ä»£ç å‚è€ƒ:**
```python
# å®ç° Layer Collaboration FF
class CollaborativeFF:
    def forward(self, x, y_onehot):
        for l in range(len(self.layers)):
            # æ ‡å‡† FF goodness
            g_local = self.compute_goodness(self.layers[l](x))
            
            # æ·»åŠ åä½œé¡¹
            if l < len(self.layers) - 1:
                g_collab = self.compute_collaboration(
                    self.layers[l], 
                    self.layers[l+1]
                )
            
            loss += g_local + alpha * g_collab
```

---

## 6. ä»£ç éœ€æ±‚

### 6.1 æ ¸å¿ƒä»£ç æ¨¡å—

```
ff-transfer-experiments/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ ff_mlp.py           # FF MLP å®ç°
â”‚   â”œâ”€â”€ ff_cnn.py           # FF CNN å®ç°
â”‚   â”œâ”€â”€ bp_baseline.py      # BP baseline
â”‚   â””â”€â”€ collaborative_ff.py # æ”¹è¿›ç‰ˆ FF
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ cka.py              # CKA è®¡ç®—
â”‚   â”œâ”€â”€ rsa.py              # RSA è®¡ç®—
â”‚   â””â”€â”€ linear_probe.py     # Linear probing
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ transfer_baseline.py    # åŸºç¡€è¿ç§»å®éªŒ
â”‚   â”œâ”€â”€ layer_analysis.py       # å±‚çº§åˆ†æ
â”‚   â””â”€â”€ feature_generality.py   # ç‰¹å¾é€šç”¨æ€§
â”œâ”€â”€ data/
â”‚   â””â”€â”€ datasets.py         # æ•°æ®åŠ è½½
â””â”€â”€ utils/
    â”œâ”€â”€ visualization.py    # å¯è§†åŒ–
    â””â”€â”€ metrics.py          # è¯„ä¼°æŒ‡æ ‡
```

### 6.2 ä¾èµ–åº“

```python
# requirements.txt
torch>=2.0
torchvision
numpy
scipy
matplotlib
seaborn
scikit-learn
pandas
tqdm
```

### 6.3 å‚è€ƒå®ç°

**FF åŸå§‹å®ç°:**
- https://github.com/mpezeshki/pytorch_forward_forward

**CKA å®ç°:**
- https://github.com/google-research/google-research/tree/master/representation_similarity

**RSA å®ç°:**
- https://github.com/rsagroup/rsatoolbox

---

## 7. é¢„æœŸç»“æœä¸å‡è®¾éªŒè¯

### 7.1 ä¸»è¦å‡è®¾

| å‡è®¾ | é¢„æœŸç»“æœ | éªŒè¯æ–¹æ³• |
|-----|---------|---------|
| H1: FF è¿ç§»æ€§èƒ½å·®äº BP | FF è¿ç§»å‡†ç¡®ç‡ä½ 5-15% | å®éªŒä¸€ |
| H2: FF æ—©æœŸå±‚ç‰¹å¾æ›´ task-specific | CKA(FF_layer1, BP_layer1) < 0.5 | å®éªŒäºŒ |
| H3: FF ç‰¹å¾åœ¨è¿œåŸŸè¿ç§»è¡°å‡æ›´å¿« | è¿ç§»æ›²çº¿æ–œç‡æ›´é™¡ | å®éªŒä¸‰ |
| H4: Layer Collaboration æ”¹å–„è¿ç§» | è¿ç§»å‡†ç¡®ç‡æå‡ 3-5% | å®éªŒå›› |

### 7.2 é¢„æœŸå‘ç°

1. **FF çš„è¿ç§»ç“¶é¢ˆåœ¨ä¸­é—´å±‚:**
   - æ—©æœŸå±‚å¯èƒ½å­¦åˆ°ç±»ä¼¼çš„ä½çº§ç‰¹å¾
   - ä¸­é—´å±‚ç”±äºç¼ºä¹åä½œï¼Œç‰¹å¾å¼€å§‹åˆ†åŒ–
   - åæœŸå±‚å®Œå…¨ task-specific

2. **FF çš„ RDM ç»“æ„ä¸åŒäº BP:**
   - FF å¯èƒ½å½¢æˆæ›´"å°–é”"çš„ç±»åˆ«è¾¹ç•Œ
   - ä½†ç¼ºä¹å±‚çº§åŒ–çš„è¯­ä¹‰ç»„ç»‡

3. **æ”¹è¿› FF çš„æ–¹å‘:**
   - æ·»åŠ å±‚é—´åä½œæœºåˆ¶
   - ä¿®æ”¹ goodness function é¼“åŠ±é€šç”¨ç‰¹å¾
   - å¼•å…¥å¯¹æ¯”å­¦ä¹ ç›®æ ‡

---

## 8. æ—¶é—´è§„åˆ’

| é˜¶æ®µ | å†…å®¹ | æ—¶é—´ |
|-----|------|-----|
| Week 1 | æ­å»ºä»£ç æ¡†æ¶ï¼Œå®ç° FF/BP baseline | 5 å¤© |
| Week 2 | å®éªŒä¸€ï¼šåŸºç¡€è¿ç§»æ€§èƒ½å¯¹æ¯” | 4 å¤© |
| Week 3 | å®éªŒäºŒï¼šCKA/RSA è¡¨å¾åˆ†æ | 5 å¤© |
| Week 4 | å®éªŒä¸‰ï¼šç‰¹å¾é€šç”¨æ€§åˆ†æ | 4 å¤© |
| Week 5 | å®éªŒå››ï¼šæ”¹è¿›å˜ä½“æµ‹è¯• | 5 å¤© |
| Week 6 | ç»“æœæ•´ç†ï¼Œè®ºæ–‡æ’°å†™ | 5 å¤© |

---

## 9. å…³é”®å‚è€ƒæ–‡çŒ®

### æ ¸å¿ƒè®ºæ–‡

1. **[Hinton, 2022]** "The Forward-Forward Algorithm: Some Preliminary Investigations" - arXiv:2212.13345

2. **[Brenig et al., 2023]** "A Study of Forward-Forward Algorithm for Self-Supervised Learning" - arXiv:2309.11955
   - **æœ€ç›´æ¥ç›¸å…³:** é¦–æ¬¡ç³»ç»Ÿç ”ç©¶ FF è¿ç§»å­¦ä¹ 

3. **[Lorberbom et al., AAAI 2024]** "Layer Collaboration in the Forward-Forward Algorithm" - arXiv:2305.12393
   - **æå‡ºè§£å†³æ–¹æ¡ˆ:** å±‚åä½œæœºåˆ¶

4. **[Yosinski et al., NeurIPS 2014]** "How transferable are features in deep neural networks?" - arXiv:1411.1792
   - **è¿ç§»å­¦ä¹ åŸºç¡€:** ç‰¹å¾é€šç”¨æ€§ vs ç‰¹å®šæ€§

### è¡¨å¾åˆ†ææ–¹æ³•

5. **[Kornblith et al., ICML 2019]** "Similarity of Neural Network Representations Revisited"
   - **CKA æ–¹æ³•ä»‹ç»**

6. **[Kriegeskorte et al., 2008]** "Representational similarity analysis"
   - **RSA æ–¹æ³•åŸå§‹è®ºæ–‡**

### FF æ”¹è¿›å·¥ä½œ

7. **[2025]** "Self-Contrastive Forward-Forward algorithm" - Nature Communications
   - **æœ€æ–°æ”¹è¿›:** è‡ªå¯¹æ¯”å­¦ä¹ 

8. **[2025]** "Scalable Forward-Forward Algorithm" - arXiv:2501.03176

9. **[2024]** "Distance-Forward Learning" - arXiv:2408.14925

---

## 10. ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³è¡ŒåŠ¨
- [ ] é˜…è¯» Brenig et al. è®ºæ–‡å…¨æ–‡ï¼ˆPDFï¼‰
- [ ] é˜…è¯» Lorberbom et al. å±‚åä½œè®ºæ–‡
- [ ] å¯»æ‰¾å¯ç”¨çš„ FF PyTorch å®ç°

### æœ¬å‘¨ç›®æ ‡
- [ ] æ­å»ºå®éªŒä»£ç æ¡†æ¶
- [ ] å¤ç°åŸºç¡€ FF è®­ç»ƒ
- [ ] è®¾è®¡è¯¦ç»†å®éªŒ protocol

### é•¿æœŸç›®æ ‡
- [ ] å®Œæˆæ‰€æœ‰å®éªŒ
- [ ] æ’°å†™ RQ1 éƒ¨åˆ†è®ºæ–‡
- [ ] ä¸ RQ2-5 æ•´åˆ

---

**æ–‡æ¡£çŠ¶æ€:** åˆç¨¿å®Œæˆ  
**æœ€åæ›´æ–°:** 2026-02-04
