"""
æ•´ç†è´Ÿæ ·æœ¬ç­–ç•¥å¯¹æ¯”å®éªŒç»“æœ
ç”Ÿæˆæœ€ç»ˆçš„ JSONã€å¯è§†åŒ–å’Œæ–‡æ¡£
"""
import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime

def load_results():
    """åŠ è½½å®éªŒç»“æœ"""
    results_path = Path(__file__).parent.parent / 'results' / 'strategy_comparison.json'
    with open(results_path, 'r') as f:
        return json.load(f)

def generate_visualization(data, output_dir):
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    results = data['results']
    
    # è¿‡æ»¤å·²å®Œæˆçš„ç­–ç•¥
    completed = {k: v for k, v in results.items() 
                 if v.get('mean_accuracy') is not None}
    
    if len(completed) < 2:
        print("Not enough completed experiments for visualization")
        return
    
    # æŒ‰å‡†ç¡®ç‡æ’åº
    sorted_names = sorted(completed.keys(), 
                         key=lambda x: completed[x]['mean_accuracy'], 
                         reverse=True)
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('è´Ÿæ ·æœ¬ç­–ç•¥å¯¹æ¯”å®éªŒç»“æœ', fontsize=14, fontweight='bold')
    
    # 1. å‡†ç¡®ç‡å¯¹æ¯”
    ax1 = axes[0, 0]
    accuracies = [completed[n]['mean_accuracy'] * 100 for n in sorted_names]
    stds = [completed[n].get('std_accuracy', 0) * 100 for n in sorted_names]
    colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(sorted_names)))[::-1]
    
    bars = ax1.barh(sorted_names, accuracies, xerr=stds, color=colors, capsize=3)
    ax1.set_xlabel('Accuracy (%)')
    ax1.set_title('æœ€ç»ˆå‡†ç¡®ç‡å¯¹æ¯”')
    ax1.set_xlim(0, 100)
    
    for bar, acc in zip(bars, accuracies):
        ax1.text(acc + 1, bar.get_y() + bar.get_height()/2, 
                f'{acc:.1f}%', va='center', fontsize=9)
    
    # 2. è®­ç»ƒæ›²çº¿
    ax2 = axes[0, 1]
    for name in sorted_names[:5]:
        if 'accuracies' in completed[name]:
            accs = completed[name]['accuracies']
            ax2.plot(range(1, len(accs)+1), [a*100 for a in accs], 
                    label=name, marker='o', markersize=4)
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.set_title('è®­ç»ƒæ›²çº¿')
    ax2.legend(fontsize=8)
    ax2.grid(True, alpha=0.3)
    
    # 3. è®­ç»ƒæ—¶é—´å¯¹æ¯”
    ax3 = axes[1, 0]
    times = [completed[n].get('mean_time', 0) for n in sorted_names]
    ax3.barh(sorted_names, times, color='steelblue')
    ax3.set_xlabel('Training Time (s)')
    ax3.set_title('è®­ç»ƒæ—¶é—´å¯¹æ¯”')
    
    # 4. ç­–ç•¥åˆ†ç±»
    ax4 = axes[1, 1]
    categories = {
        'Label Embedding': sum(1 for n in sorted_names if completed[n].get('uses_label_embedding', False)),
        'Non-Label': sum(1 for n in sorted_names if not completed[n].get('uses_label_embedding', True)),
    }
    ax4.pie(categories.values(), labels=categories.keys(), autopct='%1.1f%%', 
            colors=['#66b3ff', '#ff9999'])
    ax4.set_title('ç­–ç•¥ç±»å‹åˆ†å¸ƒ')
    
    plt.tight_layout()
    
    output_path = Path(output_dir) / 'strategy_comparison_final.png'
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"Saved visualization: {output_path}")

def generate_report(data, output_dir):
    """ç”Ÿæˆ Markdown æŠ¥å‘Š"""
    results = data['results']
    config = data.get('experiment_config', {})
    
    # è¿‡æ»¤å·²å®Œæˆçš„ç­–ç•¥
    completed = {k: v for k, v in results.items() 
                 if v.get('mean_accuracy') is not None}
    pending = {k: v for k, v in results.items() 
               if v.get('mean_accuracy') is None}
    
    sorted_strategies = sorted(
        completed.items(), 
        key=lambda x: x[1]['mean_accuracy'], 
        reverse=True
    )
    
    report = []
    report.append("# è´Ÿæ ·æœ¬ç­–ç•¥å¯¹æ¯”å®éªŒæŠ¥å‘Š")
    report.append("")
    report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    report.append("")
    
    report.append("## å®éªŒé…ç½®")
    report.append("")
    report.append(f"- **æ•°æ®é›†**: {config.get('dataset', 'MNIST')}")
    report.append(f"- **ç½‘ç»œæ¶æ„**: {config.get('architecture', '784 â†’ 500 â†’ 500')}")
    report.append(f"- **ä¼˜åŒ–å™¨**: {config.get('optimizer', 'Adam')} (lr={config.get('learning_rate', 0.03)})")
    report.append(f"- **Batch Size**: {config.get('batch_size', 64)}")
    report.append(f"- **Epochs**: {config.get('epochs', 10)}")
    report.append(f"- **è®¾å¤‡**: {config.get('device', 'mps')}")
    report.append("")
    
    report.append("## å®éªŒè¿›åº¦")
    report.append("")
    report.append(f"- **å·²å®Œæˆ**: {len(completed)}/10 ç­–ç•¥")
    report.append(f"- **å¾…å®Œæˆ**: {len(pending)}/10 ç­–ç•¥")
    report.append("")
    
    report.append("## å·²å®Œæˆç­–ç•¥æ’å")
    report.append("")
    report.append("| æ’å | ç­–ç•¥ | å‡†ç¡®ç‡ | è®­ç»ƒæ—¶é—´ | ä½¿ç”¨æ ‡ç­¾åµŒå…¥ |")
    report.append("|------|------|--------|----------|-------------|")
    
    for rank, (name, d) in enumerate(sorted_strategies, 1):
        acc = f"{d['mean_accuracy']*100:.2f}%"
        time_str = f"{d.get('mean_time', 0):.1f}s"
        label_emb = "âœ…" if d.get('uses_label_embedding', False) else "âŒ"
        report.append(f"| {rank} | {name} | {acc} | {time_str} | {label_emb} |")
    
    report.append("")
    
    if pending:
        report.append("## å¾…å®Œæˆç­–ç•¥")
        report.append("")
        for name, d in pending.items():
            status = d.get('status', 'pending')
            desc = d.get('description', '')
            report.append(f"- **{name}** ({status}): {desc}")
        report.append("")
    
    report.append("## å…³é”®å‘ç°")
    report.append("")
    
    if sorted_strategies:
        top_name, top_data = sorted_strategies[0]
        report.append(f"### ğŸ¥‡ æœ€ä½³ç­–ç•¥: {top_name}")
        report.append("")
        report.append(f"- **å‡†ç¡®ç‡**: {top_data['mean_accuracy']*100:.2f}%")
        report.append(f"- **è®­ç»ƒæ—¶é—´**: {top_data.get('mean_time', 0):.1f}s")
        if 'description' in top_data:
            report.append(f"- **æè¿°**: {top_data['description']}")
        report.append("")
    
    # åˆ†æå‘ç°
    label_emb_strategies = [n for n, d in completed.items() if d.get('uses_label_embedding', False)]
    non_label_strategies = [n for n, d in completed.items() if not d.get('uses_label_embedding', True)]
    
    report.append("### æ ‡ç­¾åµŒå…¥çš„é‡è¦æ€§")
    report.append("")
    if label_emb_strategies and non_label_strategies:
        label_emb_avg = np.mean([completed[n]['mean_accuracy'] for n in label_emb_strategies]) * 100
        non_label_avg = np.mean([completed[n]['mean_accuracy'] for n in non_label_strategies]) * 100
        report.append(f"- ä½¿ç”¨æ ‡ç­¾åµŒå…¥çš„ç­–ç•¥å¹³å‡å‡†ç¡®ç‡: **{label_emb_avg:.1f}%**")
        report.append(f"- ä¸ä½¿ç”¨æ ‡ç­¾åµŒå…¥çš„ç­–ç•¥å¹³å‡å‡†ç¡®ç‡: **{non_label_avg:.1f}%**")
        report.append(f"- å·®è·: **{label_emb_avg - non_label_avg:.1f}** ä¸ªç™¾åˆ†ç‚¹")
        report.append("")
        report.append("> **ç»“è®º**: æ ‡ç­¾åµŒå…¥å¯¹äº Forward-Forward ç®—æ³•çš„åˆ†ç±»æ€§èƒ½è‡³å…³é‡è¦ã€‚")
        report.append("> ä¸ä½¿ç”¨æ ‡ç­¾åµŒå…¥çš„ç­–ç•¥ï¼ˆå¦‚ image_mixing, random_noiseï¼‰è¾¾åˆ°æ¥è¿‘éšæœºæ°´å¹³ï¼ˆ~10%ï¼‰ï¼Œ")
        report.append("> å› ä¸ºç½‘ç»œæ— æ³•å­¦ä¹ å°†å›¾åƒä¸ç±»åˆ«å…³è”ã€‚")
    report.append("")
    
    report.append("---")
    report.append("*ç”± Forward-Forward Research è‡ªåŠ¨ç”Ÿæˆ*")
    
    output_path = Path(output_dir) / 'strategy_comparison_report.md'
    with open(output_path, 'w') as f:
        f.write('\n'.join(report))
    print(f"Saved report: {output_path}")

def main():
    print("Loading results...")
    data = load_results()
    
    output_dir = Path(__file__).parent.parent / 'results'
    
    print("\nGenerating visualization...")
    generate_visualization(data, output_dir)
    
    print("\nGenerating report...")
    generate_report(data, output_dir)
    
    print("\nDone!")

if __name__ == '__main__':
    main()
